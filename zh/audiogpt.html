<!DOCTYPE html>
<html>

<head>
    <title>Talk GPT cg8.pro</title>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="../style/normalize.css" rel="stylesheet" type="text/css" />
    <link href="../style/skeleton.css" rel="stylesheet" type="text/css" />
    <link href="../style/audiogpt.css" rel="stylesheet" type="text/css" />
</head>

<body style="background-color: black;">
    <header>
        <div style="color:white;text-align: center;margin-top: 50px;font-size: 24px;">
            Talk GPT <span style="color:grey;">by CG8</span>
        </div>
    </header>
    <div class="container main">
        <div style="text-align: center; margin-bottom: 20px;">
            <img id="assistant" class="assistant" src="../img/silent.gif" />
        </div>

    </div>
    <div class="footer">
        <div style="text-align: center; ">
            <img id="record" class="press" src="../img/btn_ready.gif" />
        </div>
        <span id="tips" style="color: white;font-size: 24px;"></span>
        <div>-</div>
        <div style="color:grey;font-size: 12px;">智慧值得多等一会</div>
    </div>
    <script src="../js/forge.min.js"></script>
    <script src="../js/FileSaver.min.js"></script>
    <script src="../js/vconsole.min.js"></script>
    <script>
        var vConsole = new window.VConsole();
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();

        let mediaRecorder;
        let audioChunks = [];
        let messages = [];
        var status = "";
        var isSpeaking = false;
        const recordButton = document.getElementById('record');
        const assistant = document.getElementById('assistant');
        const tips = document.getElementById("tips");


        tips.innerHTML = "点击，讲话"

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.addEventListener('dataavailable', function (e) {
                    if (e.data.size > 0) {
                        audioChunks.push(event.data);
                    } else {
                        console.log('no audio data available');
                    }
                });

                mediaRecorder.addEventListener("stop", () => {
                    if (audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/mpeg' });
                        console.log(audioBlob)
                        sendAudioToServer(audioBlob);
                    } else {
                        console.log('No audio data to send');
                    }
                });
            });


        recordButton.addEventListener('click', () => {
            if (isSpeaking) {
                recordButton.src = '../img/btn_ready.gif';
                audioChunks = [];
                isSpeaking = false;
                tips.innerHTML = ""
                mediaRecorder.stop();
            } else {
                recordButton.src = '../img/btn_collecting.gif';
                isSpeaking = true;
                tips.innerHTML = "你说话"
                mediaRecorder.start();
            }
        });

        function sendAudioToServer(audioBlob) {
            const reader = new FileReader();
            reader.onloadend = () => {
                const base64AudioMessage = reader.result.split(',')[1];
                assistant.src = '../img/thinking.gif';
                tips.innerHTML = "GPT思考中······";
                recordButton.style.display = "none";
                fetch('https://1320865562-jq80o0roq9-sg.scf.tencentcs.com', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        "messages": encrypt(key, iv, new TextEncoder().encode(JSON.stringify(messages))),
                        "actlike": "default",
                        "audio": base64AudioMessage,
                        "option": "6",
                        "voice": "onyx"
                    })
                })
                    .then(response => response.json())
                    .then(data => {
                        var resultMessages = JSON.parse(decrypt(key, iv, data.message));
                        messages.push(...resultMessages);
                        console.log(messages);

                        // 将 Base64 编码的字符串转换为 bytes
                        var byteCharacters = atob(data.audio);
                        var byteNumbers = new Array(byteCharacters.length);
                        for (let i = 0; i < byteCharacters.length; i++) {
                            byteNumbers[i] = byteCharacters.charCodeAt(i);
                        }
                        var byteArray = new Uint8Array(byteNumbers);

                        // Decode audio data with audio context
                        audioContext.decodeAudioData(byteArray.buffer, buffer => {

                            let source = audioContext.createBufferSource();
                            source.buffer = buffer;

                            // 连接图：音源 -> 输出（扬声器）
                            source.connect(audioContext.destination);

                            source.onended = function () {
                                assistant.src = '../img/silent.gif';
                                tips.innerHTML = "点一下，然后讲话";
                                recordButton.style.display = "inline";
                            };

                            source.onplaying = function () {
                                assistant.src = '../img/speaking.gif';
                                tips.innerHTML = "GPT 正在讲话";
                            };

                            // 播放音频
                            source.start();
                        });
                    });
            };
            reader.readAsDataURL(audioBlob);
        }

        // 用户触发事件，例如点击按钮
        function onUserTriggeredEvent() {
            audioContext.resume().then(() => {
                // 用户授予了自动播放音频的权限，现在你可以获取音频数据并播放了
                // sendAudioToServer(audioBlob);
            });
        }

        const key = "i9r8RSYSlIHjPv5EX+LTZ4b8XMvr1FMgjZYlI0uDzvg="
        const iv = "9iebtE3ryRW8CrVCI08psA=="

        // 加密
        function encrypt(keyBase64, ivBase64, data) {
            var key = forge.util.decode64(keyBase64);
            var iv = forge.util.decode64(ivBase64);
            var cipher = forge.cipher.createCipher('AES-CBC', key);
            cipher.start({ iv: iv });
            cipher.update(forge.util.createBuffer(data));
            cipher.finish();
            var encrypted = cipher.output;
            return forge.util.encode64(encrypted.getBytes());
        }

        // 解密
        function decrypt(keyBase64, ivBase64, encryptedData) {
            var key = forge.util.decode64(keyBase64);
            var iv = forge.util.decode64(ivBase64);
            var decipher = forge.cipher.createDecipher('AES-CBC', key);
            decipher.start({ iv: iv });
            decipher.update(forge.util.createBuffer(forge.util.decode64(encryptedData)));
            decipher.finish();
            return decipher.output.data;
        }
    </script>
</body>

</html>